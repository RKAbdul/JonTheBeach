{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-14T08:31:46.851830Z",
     "iopub.status.busy": "2025-05-14T08:31:46.851506Z",
     "iopub.status.idle": "2025-05-14T08:31:47.170970Z",
     "shell.execute_reply": "2025-05-14T08:31:47.170263Z",
     "shell.execute_reply.started": "2025-05-14T08:31:46.851804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Strategy Implementation\n",
    "\n",
    "PARTICIPANTS CAN USE THIS DEFAULT STRATEGY AS A STARTING POINT.\n",
    "The strategy uses moving averages and volatility to make trading decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T08:31:47.172872Z",
     "iopub.status.busy": "2025-05-14T08:31:47.172401Z",
     "iopub.status.idle": "2025-05-14T08:31:47.187812Z",
     "shell.execute_reply": "2025-05-14T08:31:47.186778Z",
     "shell.execute_reply.started": "2025-05-14T08:31:47.172842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MOVING_AVERAGE_WINDOW = 25\n",
    "VOLATILITY_THRESHOLD = 2.1\n",
    "\n",
    "class DefaultStrategy:\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        \n",
    "        # Price history for each pair - this maintains state between calls\n",
    "        self.price_history = {\n",
    "            \"token_1/fiat\": [],\n",
    "            \"token_2/fiat\": [],\n",
    "            \"token_1/token_2\": []\n",
    "        }\n",
    "        \n",
    "        # Window size for moving averages\n",
    "        self.window = MOVING_AVERAGE_WINDOW\n",
    "        \n",
    "        # Volatility threshold for signals\n",
    "        self.threshold = VOLATILITY_THRESHOLD\n",
    "\n",
    "    def on_data(self, market_data, balances):\n",
    "        \"\"\"Process market data and current balances to make trading decisions.\n",
    "        \n",
    "        Args:\n",
    "            market_data: Dictionary of {pair: tick_data} containing market data for each pair\n",
    "            balances: Dictionary of {currency: amount} containing current balances\n",
    "        \n",
    "        Returns:\n",
    "            Trading signal dict {pair, side, qty} or None\n",
    "        \"\"\"\n",
    "        orders = []\n",
    "        \n",
    "        # Update price history for each pair\n",
    "        for pair, data in market_data.items():\n",
    "            if pair in self.price_history:\n",
    "                self.price_history[pair].append(data[\"close\"])\n",
    "                # Limit history length\n",
    "                if len(self.price_history[pair]) > self.window:\n",
    "                    self.price_history[pair] = self.price_history[pair][-self.window:]\n",
    "        \n",
    "        # Wait until we have enough data points\n",
    "        for prices in self.price_history.values():\n",
    "            if len(prices) < self.window:\n",
    "                return orders\n",
    "        \n",
    "        # Initialize flag for trading\n",
    "        if not self.initialized:\n",
    "            self.initialized = True\n",
    "            return orders\n",
    "        \n",
    "        # Check for trading opportunities in token_1/fiat\n",
    "        if \"token_1/fiat\" in market_data:\n",
    "            prices = self.price_history[\"token_1/fiat\"]\n",
    "            price = prices[-1]\n",
    "            mu, sigma = np.mean(prices), np.std(prices)\n",
    "            \n",
    "            if price < mu - self.threshold * sigma:\n",
    "                # Buy token_1 with fiat if we have enough fiat\n",
    "                qty = 0.01\n",
    "                # Get fee from market_data if available, otherwise use default\n",
    "                fee = market_data[\"fee\"]\n",
    "                required_fiat = qty * price * (1 + fee)\n",
    "                if balances[\"fiat\"] >= required_fiat:\n",
    "                    orders.append({\"pair\": \"token_1/fiat\", \"side\": \"buy\", \"qty\": qty})\n",
    "            \n",
    "            elif price > mu + self.threshold * sigma:\n",
    "                # Sell token_1 for fiat if we have enough token_1\n",
    "                qty = min(0.01, balances[\"token_1\"])  # Adjust qty based on available balance\n",
    "                if qty > 0:\n",
    "                    orders.append({\"pair\": \"token_1/fiat\", \"side\": \"sell\", \"qty\": qty})\n",
    "        \n",
    "        # Check for trading opportunities in token_2/fiat\n",
    "        if \"token_2/fiat\" in market_data:\n",
    "            prices = self.price_history[\"token_2/fiat\"]\n",
    "            price = prices[-1]\n",
    "            mu, sigma = np.mean(prices), np.std(prices)\n",
    "            \n",
    "            if price < mu - self.threshold * sigma:\n",
    "                # Buy token_2 with fiat if we have enough fiat\n",
    "                qty = 0.1\n",
    "                # Get fee from market_data if available, otherwise use default\n",
    "                fee = market_data[\"fee\"]\n",
    "                required_fiat = qty * price * (1 + fee)\n",
    "                if balances[\"fiat\"] >= required_fiat:\n",
    "                    orders.append({\"pair\": \"token_2/fiat\", \"side\": \"buy\", \"qty\": qty})\n",
    "            \n",
    "            elif price > mu + self.threshold * sigma:\n",
    "                # Sell token_2 for fiat if we have enough token_2\n",
    "                qty = min(0.1, balances[\"token_2\"])  # Adjust qty based on available balance\n",
    "                if qty > 0:\n",
    "                    orders.append({\"pair\": \"token_2/fiat\", \"side\": \"sell\", \"qty\": qty})\n",
    "        \n",
    "        # Check for arbitrage opportunities with token_1/token_2\n",
    "        if all(pair in market_data for pair in [\"token_1/fiat\", \"token_2/fiat\", \"token_1/token_2\"]):\n",
    "            token1_price = market_data[\"token_1/fiat\"][\"close\"]\n",
    "            token2_price = market_data[\"token_2/fiat\"][\"close\"]\n",
    "            token1_token2_price = market_data[\"token_1/token_2\"][\"close\"]\n",
    "            \n",
    "            # Calculate implied token_1/token_2 price\n",
    "            implied_token1_token2 = token1_price / token2_price\n",
    "            \n",
    "            # If actual token_1/token_2 price is significantly lower than implied\n",
    "            if token1_token2_price < implied_token1_token2 * 0.995:\n",
    "                # Buy token_1 with token_2 (if we have token_2)\n",
    "                qty_token1 = 0.01\n",
    "                # Get fee from market_data if available, otherwise use default\n",
    "                fee = market_data[\"fee\"]\n",
    "                required_token2 = qty_token1 * token1_token2_price * (1 + fee)\n",
    "                if balances[\"token_2\"] >= required_token2:\n",
    "                    orders.append({\"pair\": \"token_1/token_2\", \"side\": \"buy\", \"qty\": qty_token1})\n",
    "            \n",
    "            # If actual token_1/token_2 price is significantly higher than implied\n",
    "            elif token1_token2_price > implied_token1_token2 * 1.005:\n",
    "                # Sell token_1 for token_2 (if we have token_1)\n",
    "                qty_token1 = min(0.01, balances[\"token_1\"])  # Adjust qty based on available balance\n",
    "                if qty_token1 > 0:\n",
    "                    orders.append({\"pair\": \"token_1/token_2\", \"side\": \"sell\", \"qty\": qty_token1})\n",
    "        \n",
    "        return orders\n",
    "\n",
    "strategy = DefaultStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File Generation\n",
    "\n",
    "PARTICIPANTS SHOULD NOT MODIFY THIS FUNCTION.\n",
    "It is part of the evaluation process to ensure the strategy works as intended.\n",
    "This function is used to validate the strategy. It runs a backtest on the strategy's performance using historical market data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T08:31:47.189120Z",
     "iopub.status.busy": "2025-05-14T08:31:47.188776Z",
     "iopub.status.idle": "2025-05-14T08:31:47.212505Z",
     "shell.execute_reply": "2025-05-14T08:31:47.211674Z",
     "shell.execute_reply.started": "2025-05-14T08:31:47.189098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_backtest(combined_data: pd.DataFrame, fee: float, balances: dict[str, float]) -> pd.DataFrame:\n",
    "    \"\"\"Run a backtest with multiple trading pairs.\n",
    "\n",
    "    Args:\n",
    "        submission_dir: Path to the strategy directory\n",
    "        combined_data: DataFrame containing market data for multiple pairs\n",
    "        fee: Trading fee (in basis points, e.g., 2 = 0.02%)\n",
    "        balances: Dictionary of {pair: amount} containing initial balances\n",
    "    \"\"\"\n",
    "    # Record initial balances for display\n",
    "    initial_balances = balances.copy()\n",
    "\n",
    "    # Initialize prices with first data point for each pair\n",
    "    combined_data.sort_values(\"timestamp\", inplace=True)\n",
    "    first_prices = {k: df.iloc[0]['close'] for k, df in combined_data.groupby(\"symbol\")}\n",
    "\n",
    "    # Calculate true initial portfolio value including all assets\n",
    "    initial_portfolio_value = initial_balances[\"fiat\"]\n",
    "    if \"token_1/fiat\" in first_prices and initial_balances[\"token_1\"] > 0:\n",
    "        initial_portfolio_value += initial_balances[\"token_1\"] * first_prices[\"token_1/fiat\"]\n",
    "    if \"token_2/fiat\" in first_prices and initial_balances[\"token_2\"] > 0:\n",
    "        initial_portfolio_value += initial_balances[\"token_2\"] * first_prices[\"token_2/fiat\"]\n",
    "\n",
    "    # Combine all dataframes and sort by timestamp\n",
    "    result = pd.DataFrame(\n",
    "        columns=[\"id\", \"timestamp\", \"pair\", \"side\", \"qty\"],\n",
    "    )\n",
    "\n",
    "    # Process data timestamp by timestamp\n",
    "    for timestamp, group in combined_data.groupby('timestamp'):\n",
    "        # Update prices for each pair in this timestamp\n",
    "        market_data = {\n",
    "            \"fee\": fee,\n",
    "        }\n",
    "        for _, row in group.iterrows():\n",
    "            pair = row['symbol']\n",
    "            data_dict = row.to_dict()\n",
    "            # Add fee information to market data so strategies can access it\n",
    "            market_data[pair] = data_dict\n",
    "        \n",
    "        # Get strategy decision based on all available market data and current balances\n",
    "        orders = strategy.on_data(market_data, balances)\n",
    "\n",
    "        # Handle list of orders\n",
    "        for order in orders:\n",
    "            order[\"timestamp\"] = timestamp\n",
    "            order[\"id\"] = str(uuid.uuid4())\n",
    "            result = pd.concat([result, pd.DataFrame([order])], ignore_index=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T08:31:47.213679Z",
     "iopub.status.busy": "2025-05-14T08:31:47.213422Z",
     "iopub.status.idle": "2025-05-14T08:31:48.166129Z",
     "shell.execute_reply": "2025-05-14T08:31:48.165240Z",
     "shell.execute_reply.started": "2025-05-14T08:31:47.213660Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/input/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m BALANCE_TOKEN2 \u001b[38;5;241m=\u001b[39m HYPERPARAMETERS\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken2_balance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m      8\u001b[0m OUTPUT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/input/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Run the backtest on the provided test data with a fee of 0.02% and initial balances of 10,000 fiat, and 0 token_1 and token_2\u001b[39;00m\n\u001b[0;32m     13\u001b[0m result \u001b[38;5;241m=\u001b[39m run_backtest(combined_data, FEE, {\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiat\u001b[39m\u001b[38;5;124m\"\u001b[39m: BALANCE_FIAT,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: BALANCE_TOKEN1,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_2\u001b[39m\u001b[38;5;124m\"\u001b[39m: BALANCE_TOKEN2,\n\u001b[0;32m     17\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\rafey\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\rafey\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\rafey\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\rafey\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\rafey\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input/test.csv'"
     ]
    }
   ],
   "source": [
    "with open(\"./input/hyperparameters.json\") as f:\n",
    "    HYPERPARAMETERS = json.load(f)\n",
    "    \n",
    "FEE = HYPERPARAMETERS.get(\"fee\", 3.0)\n",
    "BALANCE_FIAT = HYPERPARAMETERS.get(\"fiat_balance\", 10000.0)\n",
    "BALANCE_TOKEN1 = HYPERPARAMETERS.get(\"token1_balance\", 0.0)\n",
    "BALANCE_TOKEN2 = HYPERPARAMETERS.get(\"token2_balance\", 0.0)\n",
    "OUTPUT = \"submission.csv\"\n",
    "\n",
    "combined_data = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "# Run the backtest on the provided test data with a fee of 0.02% and initial balances of 10,000 fiat, and 0 token_1 and token_2\n",
    "result = run_backtest(combined_data, FEE, {\n",
    "    \"fiat\": BALANCE_FIAT,\n",
    "    \"token_1\": BALANCE_TOKEN1,\n",
    "    \"token_2\": BALANCE_TOKEN2,\n",
    "})\n",
    "\n",
    "# Output the backtest result to a CSV file for submission\n",
    "result.to_csv(OUTPUT, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12296217,
     "sourceId": 100329,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
